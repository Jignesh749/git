{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9dd52e6-596a-411b-b0a8-4be8bfa64b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.82\n",
      "Model and scaler saved to disk.\n"
     ]
    }
   ],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Spotify API credentials\n",
    "scope = \"user-top-read user-library-read\"  # Include both user-top-read and user-library-read scopes\n",
    "client_id = \"716c1e25d0b94ad59424c2fe6e5268ec\"\n",
    "client_secret = \"1f967480693941c69c6265ca6d920b4f\"\n",
    "redirect_uri = \"http://localhost:8000/callback\"\n",
    "\n",
    "# Initialize Spotify client\n",
    "scope = \"user-top-read\"\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(client_id=client_id, client_secret=client_secret, redirect_uri=redirect_uri, scope=scope))\n",
    "\n",
    "# Function to fetch training data from Spotify API\n",
    "def fetch_training_data(limit=50):  # Adjusted limit to maximum allowed value of 50\n",
    "    try:\n",
    "        # Fetch user's top tracks\n",
    "        top_tracks = sp.current_user_top_tracks(limit=limit)\n",
    "    except spotipy.exceptions.SpotifyException as e:\n",
    "        print(f\"Spotify API error: {e}\")\n",
    "        return None  # Return None if there's an API error\n",
    "\n",
    "    track_ids = [track['id'] for track in top_tracks['items']]\n",
    "\n",
    "    # Fetch audio features and popularity for each track\n",
    "    data = []\n",
    "    for track_id in track_ids:\n",
    "        features = sp.audio_features([track_id])[0]\n",
    "        track_info = sp.track(track_id)\n",
    "        popularity = track_info['popularity']\n",
    "        \n",
    "        if features:\n",
    "            # Combine audio features and popularity into a single dictionary\n",
    "            features['popularity'] = popularity\n",
    "            data.append(features)\n",
    "    \n",
    "    # Convert data to a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Function to preprocess data\n",
    "def preprocess_data(df):\n",
    "    # Drop unnecessary columns and handle missing values\n",
    "    df = df.drop(columns=['type', 'id', 'uri', 'track_href', 'analysis_url', 'time_signature'])\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    df[df.columns] = scaler.fit_transform(df[df.columns])\n",
    "    \n",
    "    return df, scaler\n",
    "\n",
    "# Function to train and save the model\n",
    "def train_and_save_model():\n",
    "    # Fetch training data\n",
    "    df = fetch_training_data(limit=50)  # Use the adjusted limit of 50\n",
    "    \n",
    "    # Check if the data is retrieved successfully\n",
    "    if df is None:\n",
    "        print(\"Failed to fetch training data. Check the Spotify API error above.\")\n",
    "        return\n",
    "    \n",
    "    # Preprocess data\n",
    "    df, scaler = preprocess_data(df)\n",
    "    \n",
    "    # Separate features and target (popularity)\n",
    "    X = df.drop(columns=['popularity'])\n",
    "    y = df['popularity']\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train a RandomForestRegressor\n",
    "    model = RandomForestRegressor(n_estimators=50)  # Use fewer estimators for faster training\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "    \n",
    "    # Save the trained model and scaler\n",
    "    joblib.dump(model, 'spotify_model.joblib')\n",
    "    joblib.dump(scaler, 'spotify_scaler.joblib')\n",
    "    print(\"Model and scaler saved to disk.\")\n",
    "    \n",
    "# Run the function to train and save the model\n",
    "train_and_save_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16e8a9f8-a56c-46fb-902d-2a9bf2840d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import joblib  # To save the trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62ff7ac8-ca41-4f52-9886-7f314721a7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error with optimized RandomForest: 0.88\n",
      "Optimized model and scaler saved to disk.\n"
     ]
    }
   ],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Spotify API credentials\n",
    "scope = \"user-top-read user-library-read\"  # Include both user-top-read and user-library-read scopes\n",
    "client_id = \"716c1e25d0b94ad59424c2fe6e5268ec\"\n",
    "client_secret = \"1f967480693941c69c6265ca6d920b4f\"\n",
    "redirect_uri = \"http://localhost:8000/callback\"\n",
    "\n",
    "# Initialize Spotify client\n",
    "scope = \"user-top-read\"\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(client_id=client_id, client_secret=client_secret, redirect_uri=redirect_uri, scope=scope))\n",
    "\n",
    "# Function to fetch training data from Spotify API\n",
    "def fetch_training_data(limit=50):  # Adjusted limit to maximum allowed value of 50\n",
    "    try:\n",
    "        # Fetch user's top tracks\n",
    "        top_tracks = sp.current_user_top_tracks(limit=limit)\n",
    "    except spotipy.exceptions.SpotifyException as e:\n",
    "        print(f\"Spotify API error: {e}\")\n",
    "        return None  # Return None if there's an API error\n",
    "\n",
    "    track_ids = [track['id'] for track in top_tracks['items']]\n",
    "\n",
    "    # Fetch audio features and popularity for each track\n",
    "    data = []\n",
    "    for track_id in track_ids:\n",
    "        features = sp.audio_features([track_id])[0]\n",
    "        track_info = sp.track(track_id)\n",
    "        popularity = track_info['popularity']\n",
    "        \n",
    "        if features:\n",
    "            # Combine audio features and popularity into a single dictionary\n",
    "            features['popularity'] = popularity\n",
    "            data.append(features)\n",
    "    \n",
    "    # Convert data to a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Function to preprocess data\n",
    "def preprocess_data(df):\n",
    "    # Drop unnecessary columns and handle missing values\n",
    "    df = df.drop(columns=['type', 'id', 'uri', 'track_href', 'analysis_url', 'time_signature'])\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    df[df.columns] = scaler.fit_transform(df[df.columns])\n",
    "    \n",
    "    return df, scaler\n",
    "\n",
    "# Function to train and optimize the model using GridSearchCV\n",
    "def train_and_optimize_model():\n",
    "    # Fetch training data\n",
    "    df = fetch_training_data(limit=50)  # Use the adjusted limit of 50\n",
    "    \n",
    "    # Check if the data is retrieved successfully\n",
    "    if df is None:\n",
    "        print(\"Failed to fetch training data. Check the Spotify API error above.\")\n",
    "        return\n",
    "    \n",
    "    # Preprocess data\n",
    "    df, scaler = preprocess_data(df)\n",
    "    \n",
    "    # Separate features and target (popularity)\n",
    "    X = df.drop(columns=['popularity'])\n",
    "    y = df['popularity']\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Define parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 150],\n",
    "        'max_depth': [10, 15, 20],\n",
    "        'min_samples_split': [2, 4, 6],\n",
    "        'min_samples_leaf': [1, 2, 4],\n",
    "    }\n",
    "    \n",
    "    # Initialize RandomForestRegressor and GridSearchCV\n",
    "    model = RandomForestRegressor(random_state=42)\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "    \n",
    "    # Perform hyperparameter tuning\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Evaluate the best model on the testing set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(f\"Mean Absolute Error with optimized RandomForest: {mae:.2f}\")\n",
    "    \n",
    "    # Save the best model and scaler\n",
    "    joblib.dump(best_model, 'spotify_optimized_model.joblib')\n",
    "    joblib.dump(scaler, 'spotify_scaler.joblib')\n",
    "    print(\"Optimized model and scaler saved to disk.\")\n",
    "    \n",
    "# Run the function to train and optimize the model\n",
    "train_and_optimize_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa00d48a-0c76-4ab6-b52c-f13cacdd56b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jimmyvaghela/anaconda3/lib/python3.11/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 11 features, but StandardScaler is expecting 13 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 83\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 83\u001b[0m     playlist_id, track_names \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_personalized_playlist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPersonalized playlist created with ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplaylist_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrack names added to the personalized playlist:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[24], line 63\u001b[0m, in \u001b[0;36mcreate_personalized_playlist\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m filtered_features \u001b[38;5;241m=\u001b[39m [features[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m expected_features]\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Standardize the filtered features using the loaded scaler\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m standardized_features \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfiltered_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Predict popularity using the trained model\u001b[39;00m\n\u001b[1;32m     66\u001b[0m predicted_popularity \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(standardized_features)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:1006\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1003\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1005\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m-> 1006\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:626\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    623\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:415\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    418\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 11 features, but StandardScaler is expecting 13 features as input."
     ]
    }
   ],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "import joblib\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# Spotify API credentials\n",
    "scope = \"playlist-modify-private playlist-modify-public user-top-read\"\n",
    "client_id = \"your_client_id\"\n",
    "client_secret = \"your_client_secret\"\n",
    "redirect_uri = \"your_redirect_uri\"\n",
    "\n",
    "# Initialize Spotify client\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(client_id=client_id, client_secret=client_secret, redirect_uri=redirect_uri, scope=scope))\n",
    "\n",
    "# Load the saved model and scaler\n",
    "model = joblib.load('spotify_model.joblib')\n",
    "scaler = joblib.load('spotify_scaler.joblib')\n",
    "\n",
    "# Define the expected feature columns used during training\n",
    "expected_features = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "\n",
    "def create_personalized_playlist():\n",
    "    # Fetch user's top tracks\n",
    "    top_tracks = sp.current_user_top_tracks(limit=20)\n",
    "    track_ids = [track['id'] for track in top_tracks['items']]\n",
    "    track_names = [track['name'] for track in top_tracks['items']]\n",
    "\n",
    "    # Get genres from top tracks\n",
    "    artist_ids = [track['artists'][0]['id'] for track in top_tracks['items']]\n",
    "    genres = []\n",
    "    for artist_id in artist_ids:\n",
    "        artist_info = sp.artist(artist_id)\n",
    "        genres.extend(artist_info['genres'])\n",
    "    \n",
    "    genre_count = Counter(genres)\n",
    "    most_common_genre = genre_count.most_common(1)[0][0]\n",
    "\n",
    "    # Search for tracks in the most common genre\n",
    "    results = sp.search(q=f'genre:{most_common_genre}', type='track', limit=20)\n",
    "    recommended_tracks = results['tracks']['items']\n",
    "\n",
    "    # Create a new playlist for the user\n",
    "    user_id = sp.current_user()['id']\n",
    "    playlist = sp.user_playlist_create(user_id, 'Personalized Playlist', public=False)\n",
    "    playlist_id = playlist['id']\n",
    "\n",
    "    # Prepare the data for prediction\n",
    "    track_data = []\n",
    "    for track in recommended_tracks:\n",
    "        track_id = track['id']\n",
    "        track_name = track['name']\n",
    "        \n",
    "        # Fetch audio features for the track\n",
    "        features = sp.audio_features([track_id])[0]\n",
    "        \n",
    "        # Ensure features match the expected features\n",
    "        if features:\n",
    "            # Filter the features to include only the expected features\n",
    "            filtered_features = [features[key] for key in expected_features]\n",
    "            \n",
    "            # Standardize the filtered features using the loaded scaler\n",
    "            standardized_features = scaler.transform([filtered_features])\n",
    "            \n",
    "            # Predict popularity using the trained model\n",
    "            predicted_popularity = model.predict(standardized_features)[0]\n",
    "            \n",
    "            # Append track data with predicted popularity\n",
    "            track_data.append({'id': track_id, 'name': track_name, 'predicted_popularity': predicted_popularity})\n",
    "\n",
    "    # Sort the tracks based on predicted popularity\n",
    "    track_data.sort(key=lambda x: x['predicted_popularity'], reverse=True)\n",
    "\n",
    "    # Add sorted recommended tracks to the new playlist based on popularity\n",
    "    sorted_track_ids = [track['id'] for track in track_data]\n",
    "    sp.playlist_add_items(playlist_id, sorted_track_ids)\n",
    "\n",
    "    # Return the playlist ID and track names\n",
    "    return playlist_id, [track['name'] for track in track_data]\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    playlist_id, track_names = create_personalized_playlist()\n",
    "    print(f\"Personalized playlist created with ID: {playlist_id}\")\n",
    "    print(\"Track names added to the personalized playlist:\")\n",
    "    for name in track_names:\n",
    "        print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61f7b5e3-d688-4b46-a02c-756ea3919517",
   "metadata": {},
   "outputs": [
    {
     "ename": "SpotifyException",
     "evalue": "http status: 400, code:-1 - Unsupported URL / URI., reason: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSpotifyException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Example usage: predict popularity of tracks\u001b[39;00m\n\u001b[1;32m     60\u001b[0m track_ids \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrack_id_1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrack_id_2\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Replace with your track IDs\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_popularity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrack_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted popularities: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredictions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[28], line 48\u001b[0m, in \u001b[0;36mpredict_popularity\u001b[0;34m(track_ids)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_popularity\u001b[39m(track_ids):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# Fetch input data for prediction\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_input_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrack_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# Separate features and target\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     X \u001b[38;5;241m=\u001b[39m input_data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpopularity\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[28], line 27\u001b[0m, in \u001b[0;36mfetch_input_data\u001b[0;34m(track_ids)\u001b[0m\n\u001b[1;32m     25\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m track_id \u001b[38;5;129;01min\u001b[39;00m track_ids:\n\u001b[0;32m---> 27\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrack_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     28\u001b[0m     track_info \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mtrack(track_id)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m features:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spotipy/client.py:1736\u001b[0m, in \u001b[0;36mSpotify.audio_features\u001b[0;34m(self, tracks)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio-features/?ids=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m trackid)\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     tlist \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_id\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrack\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtracks\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1737\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio-features/?ids=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(tlist))\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;66;03m# the response has changed, look for the new style first, and if\u001b[39;00m\n\u001b[1;32m   1739\u001b[0m \u001b[38;5;66;03m# its not there, fallback on the old style\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spotipy/client.py:1736\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio-features/?ids=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m trackid)\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     tlist \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_id\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrack\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tracks]\n\u001b[1;32m   1737\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio-features/?ids=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(tlist))\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;66;03m# the response has changed, look for the new style first, and if\u001b[39;00m\n\u001b[1;32m   1739\u001b[0m \u001b[38;5;66;03m# its not there, fallback on the old style\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/spotipy/client.py:1990\u001b[0m, in \u001b[0;36mSpotify._get_id\u001b[0;34m(self, type, id)\u001b[0m\n\u001b[1;32m   1987\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mid\u001b[39m\n\u001b[1;32m   1989\u001b[0m \u001b[38;5;66;03m# TODO change to a ValueError in v3\u001b[39;00m\n\u001b[0;32m-> 1990\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m SpotifyException(\u001b[38;5;241m400\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported URL / URI.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mSpotifyException\u001b[0m: http status: 400, code:-1 - Unsupported URL / URI., reason: None"
     ]
    }
   ],
   "source": [
    "# Required packages:\n",
    "# - spotipy for interacting with Spotify's API\n",
    "# - surprise for collaborative filtering and recommendation systems\n",
    "# - pandas for data manipulation and analysis\n",
    "# - joblib for saving and loading models\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "from surprise import SVD, Dataset, Reader, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Define the scope of access\n",
    "scope = \"user-library-read playlist-modify-public user-top-read\"\n",
    "\n",
    "# Authenticate with Spotify\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(scope=scope))\n",
    "\n",
    "# Function to get user's saved tracks\n",
    "def get_user_tracks(sp, limit=50):\n",
    "    tracks = []\n",
    "    results = sp.current_user_saved_tracks(limit=limit)\n",
    "    while results:\n",
    "        for item in results['items']:\n",
    "            track = item['track']\n",
    "            tracks.append(track)\n",
    "        if results['next']:\n",
    "            results = sp.next(results)\n",
    "        else:\n",
    "            break\n",
    "    return tracks\n",
    "\n",
    "# Function to get user's top tracks\n",
    "def get_user_top_tracks(sp, time_range='medium_term', limit=50):\n",
    "    top_tracks = sp.current_user_top_tracks(time_range=time_range, limit=limit)\n",
    "    return [track['id'] for track in top_tracks['items']]\n",
    "\n",
    "# Retrieve user tracks and top tracks\n",
    "user_tracks = get_user_tracks(sp, limit=100)\n",
    "top_tracks = get_user_top_tracks(sp, time_range='medium_term', limit=50)\n",
    "\n",
    "# Function to create an interaction matrix\n",
    "def create_interaction_matrix(user_tracks, top_tracks):\n",
    "    data = {\n",
    "        'user_id': [],\n",
    "        'track_id': [],\n",
    "        'rating': []\n",
    "    }\n",
    "    user_id = sp.current_user()['id']\n",
    "\n",
    "    # Add top tracks as high ratings\n",
    "    for track_id in top_tracks:\n",
    "        data['user_id'].append(user_id)\n",
    "        data['track_id'].append(track_id)\n",
    "        data['rating'].append(5)  # High rating for top tracks\n",
    "\n",
    "    # Add user tracks as neutral ratings\n",
    "    for track in user_tracks:\n",
    "        track_id = track['id']\n",
    "        if track_id not in top_tracks:\n",
    "            data['user_id'].append(user_id)\n",
    "            data['track_id'].append(track_id)\n",
    "            data['rating'].append(3)  # Neutral rating for user tracks\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Create an interaction matrix\n",
    "interaction_matrix = create_interaction_matrix(user_tracks, top_tracks)\n",
    "\n",
    "# Create a Reader and load the data into a Dataset\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(interaction_matrix[['user_id', 'track_id', 'rating']], reader)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Train a Singular Value Decomposition (SVD) model\n",
    "model = SVD()\n",
    "model.fit(trainset)\n",
    "\n",
    "# Test the model\n",
    "predictions = model.test(testset)\n",
    "print(f\"RMSE: {accuracy.rmse(predictions)}\")\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(model, 'playlist_recommender_model.joblib')\n",
    "\n",
    "# Function to recommend tracks\n",
    "def recommend_tracks(model, sp, num_recommendations=20):\n",
    "    user_id = sp.current_user()['id']\n",
    "    track_pool = interaction_matrix['track_id'].unique()\n",
    "    \n",
    "    # Recommend tracks based on the user's profile\n",
    "    recommendations = []\n",
    "    for track_id in track_pool:\n",
    "        prediction = model.predict(user_id, track_id)\n",
    "        recommendations.append((track_id, prediction.est))\n",
    "    \n",
    "    # Sort recommendations by predicted rating\n",
    "    recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "    recommended_track_ids = [rec[0] for rec in recommendations[:num_recommendations]]\n",
    "    \n",
    "    return recommended_track_ids\n",
    "\n",
    "# Function to create a playlist\n",
    "def create_playlist(sp, name, track_ids):\n",
    "    # Create a new playlist\n",
    "    user_id = sp.current_user()['id']\n",
    "    playlist = sp.user_playlist_create(user_id, name, public=True)\n",
    "    \n",
    "    # Add tracks to the playlist\n",
    "    sp.playlist_add_items(playlist['id'], track_ids)\n",
    "    return playlist\n",
    "\n",
    "# Recommend tracks and create a playlist\n",
    "recommended_track_ids = recommend_tracks(model, sp)\n",
    "playlist_name = \"Recommended Playlist\"\n",
    "playlist = create_playlist(sp, playlist_name, recommended_track_ids)\n",
    "print(f\"Playlist created: {playlist['name']} (ID: {playlist['id']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab55f80e-a06d-4285-b82c-35b4911ad8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spotify API credentials\n",
    "scope = \"user-top-read user-library-read\"  # Include both user-top-read and user-library-read scopes\n",
    "client_id = \"716c1e25d0b94ad59424c2fe6e5268ec\"\n",
    "client_secret = \"1f967480693941c69c6265ca6d920b4f\"\n",
    "redirect_uri = \"http://localhost:8000/callback\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
